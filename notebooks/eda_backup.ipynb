{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd48e57",
   "metadata": {},
   "source": [
    "# Bitcoin Trading Sentiment Analysis: Exploring Market Sentiment vs Trader Performance\n",
    "\n",
    "## Objective\n",
    "Explore the relationship between Bitcoin market sentiment (Fear/Greed Index) and trader performance on Hyperliquid. Our goal is to uncover hidden patterns and deliver actionable insights for smarter trading strategies.\n",
    "\n",
    "---\n",
    "\n",
    "## Datasets\n",
    "1. **Fear/Greed Index**: Date, Classification (Fear/Greed)\n",
    "2. **Hyperliquid Historical Trader Data**: account, symbol, execution price, size, side, time, start position, event, closedPnL, leverage, etc.\n",
    "\n",
    "---\n",
    "\n",
    "**Analysis Pipeline:**\n",
    "1. Load and explore datasets\n",
    "2. Data preprocessing and cleaning\n",
    "3. Merge datasets on date/time\n",
    "4. Exploratory data analysis\n",
    "5. Sentiment distribution analysis\n",
    "6. Trader performance metrics\n",
    "7. Correlation analysis: sentiment vs performance\n",
    "8. Pattern discovery and feature engineering\n",
    "9. Visualize key insights\n",
    "10. Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3cf93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.insert(0, str(Path('../src').resolve()))\n",
    "\n",
    "# Configure plotting\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbcc965",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pnl_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Visualize performance by sentiment\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpnl_col\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m merged_df.columns:\n\u001b[32m      3\u001b[39m     fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m16\u001b[39m, \u001b[32m12\u001b[39m))\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Box plot: PnL by Sentiment\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'pnl_col' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize performance by sentiment\n",
    "if pnl_col and 'sentiment' in merged_df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Box plot: PnL by Sentiment\n",
    "    merged_df.boxplot(column=pnl_col, by='sentiment', ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('PnL Distribution by Sentiment', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Sentiment')\n",
    "    axes[0, 0].set_ylabel('PnL ($)')\n",
    "    axes[0, 0].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.sca(axes[0, 0])\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Bar chart: Mean PnL by Sentiment\n",
    "    mean_pnl = merged_df.groupby('sentiment')[pnl_col].mean()\n",
    "    axes[0, 1].bar(mean_pnl.index, mean_pnl.values, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].set_title('Average PnL by Sentiment', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Sentiment')\n",
    "    axes[0, 1].set_ylabel('Average PnL ($)')\n",
    "    axes[0, 1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    # Win Rate by Sentiment\n",
    "    win_rate_by_sent = merged_df.groupby('sentiment').apply(\n",
    "        lambda x: (x[pnl_col] > 0).sum() / len(x) * 100\n",
    "    )\n",
    "    axes[1, 0].bar(win_rate_by_sent.index, win_rate_by_sent.values, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[1, 0].set_title('Win Rate by Sentiment', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Sentiment')\n",
    "    axes[1, 0].set_ylabel('Win Rate (%)')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    axes[1, 0].set_ylim(0, 100)\n",
    "    \n",
    "    # Violin plot: PnL distribution by Sentiment\n",
    "    sentiment_order = sorted(merged_df['sentiment'].dropna().unique())\n",
    "    sns.violinplot(data=merged_df, x='sentiment', y=pnl_col, order=sentiment_order, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('PnL Distribution (Violin) by Sentiment', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Sentiment')\n",
    "    axes[1, 1].set_ylabel('PnL ($)')\n",
    "    axes[1, 1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4375144",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "### Recap of Findings\n",
    "\n",
    "This analysis explored the relationship between Bitcoin market sentiment (Fear/Greed Index) and trader performance on Hyperliquid. Key areas investigated:\n",
    "\n",
    "1. **Data Overview**: Loaded and validated both datasets\n",
    "2. **Preprocessing**: Cleaned, aligned, and merged sentiment with trading data\n",
    "3. **Sentiment Patterns**: Analyzed distribution and duration of Fear/Greed periods\n",
    "4. **Performance Metrics**: Calculated win rates, PnL, leverage usage\n",
    "5. **Correlations**: Examined relationships between sentiment and performance\n",
    "6. **Lag Effects**: Tested whether past sentiment predicts current performance\n",
    "7. **Transitions**: Analyzed performance during sentiment shifts\n",
    "8. **Statistical Tests**: Validated findings with hypothesis testing\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Build Predictive Models**: Use engineered features to predict PnL\n",
    "2. **Trader Segmentation**: Cluster traders by behavior patterns\n",
    "3. **Strategy Development**: Design counter-trend vs trend-following strategies\n",
    "4. **Real-time Integration**: Connect to live sentiment feeds\n",
    "5. **Backtesting**: Validate strategies with historical simulations\n",
    "\n",
    "### How to Export Results\n",
    "\n",
    "```python\n",
    "# Save merged dataset\n",
    "merged_enriched.to_csv('../deliverables/merged_sentiment_trading_data.csv', index=False)\n",
    "\n",
    "# Save key metrics\n",
    "perf_by_sentiment.to_csv('../deliverables/performance_by_sentiment.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14738bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA - Test if PnL differs across ALL sentiment categories\n",
    "if pnl_col and 'sentiment' in merged_df.columns:\n",
    "    sentiment_groups = [merged_df[merged_df['sentiment'] == sent][pnl_col].dropna() \n",
    "                       for sent in merged_df['sentiment'].dropna().unique()]\n",
    "    \n",
    "    # Filter out empty groups\n",
    "    sentiment_groups = [group for group in sentiment_groups if len(group) > 0]\n",
    "    \n",
    "    if len(sentiment_groups) >= 2:\n",
    "        f_stat, anova_pvalue = scipy_stats.f_oneway(*sentiment_groups)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ANOVA TEST: PnL Across All Sentiment Categories\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nH0: All sentiment categories have equal mean PnL\")\n",
    "        print(f\"H1: At least one sentiment category differs\\n\")\n",
    "        print(f\"F-statistic: {f_stat:.4f}\")\n",
    "        print(f\"P-value: {anova_pvalue:.4f}\")\n",
    "        print(f\"Result: {'SIGNIFICANT' if anova_pvalue < 0.05 else 'NOT SIGNIFICANT'} at Œ±=0.05\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if anova_pvalue < 0.05:\n",
    "            print(\"\\n‚úì Significant difference detected! Further post-hoc analysis recommended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis Test: Are PnL differences between Fear and Greed significant?\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "if pnl_col and 'sentiment' in merged_df.columns:\n",
    "    fear_data = merged_df[merged_df['sentiment'].str.contains('Fear', na=False)][pnl_col].dropna()\n",
    "    greed_data = merged_df[merged_df['sentiment'].str.contains('Greed', na=False)][pnl_col].dropna()\n",
    "    \n",
    "    if len(fear_data) > 0 and len(greed_data) > 0:\n",
    "        # T-test\n",
    "        t_stat, p_value = scipy_stats.ttest_ind(fear_data, greed_data)\n",
    "        \n",
    "        # Mann-Whitney U test (non-parametric alternative)\n",
    "        u_stat, u_pvalue = scipy_stats.mannwhitneyu(fear_data, greed_data, alternative='two-sided')\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"HYPOTHESIS TEST: Fear vs Greed Performance\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nH0: No difference in PnL between Fear and Greed periods\")\n",
    "        print(f\"H1: Significant difference exists\\n\")\n",
    "        \n",
    "        print(f\"Fear Sentiment:\")\n",
    "        print(f\"  Sample size: {len(fear_data)}\")\n",
    "        print(f\"  Mean PnL: ${fear_data.mean():.2f}\")\n",
    "        print(f\"  Median PnL: ${fear_data.median():.2f}\")\n",
    "        print(f\"  Std Dev: ${fear_data.std():.2f}\")\n",
    "        \n",
    "        print(f\"\\nGreed Sentiment:\")\n",
    "        print(f\"  Sample size: {len(greed_data)}\")\n",
    "        print(f\"  Mean PnL: ${greed_data.mean():.2f}\")\n",
    "        print(f\"  Median PnL: ${greed_data.median():.2f}\")\n",
    "        print(f\"  Std Dev: ${greed_data.std():.2f}\")\n",
    "        \n",
    "        print(f\"\\nIndependent T-Test:\")\n",
    "        print(f\"  T-statistic: {t_stat:.4f}\")\n",
    "        print(f\"  P-value: {p_value:.4f}\")\n",
    "        print(f\"  Result: {'SIGNIFICANT' if p_value < 0.05 else 'NOT SIGNIFICANT'} at Œ±=0.05\")\n",
    "        \n",
    "        print(f\"\\nMann-Whitney U Test (non-parametric):\")\n",
    "        print(f\"  U-statistic: {u_stat:.4f}\")\n",
    "        print(f\"  P-value: {u_pvalue:.4f}\")\n",
    "        print(f\"  Result: {'SIGNIFICANT' if u_pvalue < 0.05 else 'NOT SIGNIFICANT'} at Œ±=0.05\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        \n",
    "        # Visualization\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        axes[0].hist(fear_data, bins=50, alpha=0.6, label='Fear', edgecolor='black', color='red')\n",
    "        axes[0].hist(greed_data, bins=50, alpha=0.6, label='Greed', edgecolor='black', color='green')\n",
    "        axes[0].set_title('PnL Distribution: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('PnL ($)')\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(alpha=0.3)\n",
    "        \n",
    "        axes[1].boxplot([fear_data, greed_data], labels=['Fear', 'Greed'])\n",
    "        axes[1].set_title('PnL Comparison: Fear vs Greed', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_ylabel('PnL ($)')\n",
    "        axes[1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "        axes[1].grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Insufficient data for Fear vs Greed comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea774320",
   "metadata": {},
   "source": [
    "## 10. Statistical Analysis\n",
    "\n",
    "Perform hypothesis testing to validate our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D scatter plot: Sentiment, Leverage, PnL (if leverage available)\n",
    "leverage_cols = [col for col in merged_df.columns if 'leverage' in col.lower()]\n",
    "\n",
    "if pnl_col and 'sentiment_numeric' in merged_df.columns and leverage_cols:\n",
    "    leverage_col = leverage_cols[0]\n",
    "    \n",
    "    # Sample data if too large (for performance)\n",
    "    sample_size = min(5000, len(merged_df))\n",
    "    sample_df = merged_df.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    fig = px.scatter_3d(sample_df, x='sentiment_numeric', y=leverage_col, z=pnl_col,\n",
    "                        color=pnl_col, color_continuous_scale='RdYlGn',\n",
    "                        title=f'3D View: Sentiment vs Leverage vs PnL (Sample: {sample_size} records)',\n",
    "                        labels={'sentiment_numeric': 'Sentiment', \n",
    "                               leverage_col: 'Leverage', \n",
    "                               pnl_col: 'PnL ($)'},\n",
    "                        hover_data=['date'] if 'date' in sample_df.columns else None)\n",
    "    \n",
    "    fig.update_layout(height=700)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive scatter: Daily PnL vs Sentiment with trend line\n",
    "if pnl_col and 'sentiment_numeric' in merged_df.columns:\n",
    "    daily_data = merged_df.groupby('date').agg({\n",
    "        pnl_col: 'sum',\n",
    "        'sentiment_numeric': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    fig = px.scatter(daily_data, x='sentiment_numeric', y=pnl_col,\n",
    "                     title='Daily PnL vs Sentiment (with Trendline)',\n",
    "                     labels={'sentiment_numeric': 'Sentiment', pnl_col: 'Daily PnL ($)'},\n",
    "                     trendline='ols', trendline_color_override='red',\n",
    "                     hover_data=['date'])\n",
    "    \n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Break-even\")\n",
    "    fig.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Neutral\")\n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ecabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive time series: PnL and Sentiment overlay\n",
    "if pnl_col and 'date' in merged_df.columns and 'sentiment_numeric' in merged_df.columns:\n",
    "    daily_agg = merged_df.groupby('date').agg({\n",
    "        pnl_col: 'sum',\n",
    "        'sentiment_numeric': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily_agg['cumulative_pnl'] = daily_agg[pnl_col].cumsum()\n",
    "    \n",
    "    # Create subplot with dual y-axes\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add cumulative PnL\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=daily_agg['date'], y=daily_agg['cumulative_pnl'], \n",
    "                   name='Cumulative PnL', mode='lines', line=dict(width=2)),\n",
    "        secondary_y=False\n",
    "    )\n",
    "    \n",
    "    # Add sentiment\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=daily_agg['date'], y=daily_agg['sentiment_numeric'], \n",
    "                   name='Sentiment', mode='lines', line=dict(dash='dot', color='orange', width=2)),\n",
    "        secondary_y=True\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\")\n",
    "    fig.update_yaxes(title_text=\"Cumulative PnL ($)\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Sentiment (Numeric)\", secondary_y=True)\n",
    "    fig.update_layout(title_text=\"Trading Performance vs Market Sentiment Over Time\", \n",
    "                      height=600, hovermode='x unified')\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2143c",
   "metadata": {},
   "source": [
    "## 9. Visualize Key Insights\n",
    "\n",
    "Create comprehensive interactive visualizations with Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of week patterns\n",
    "if 'day_of_week' in merged_enriched.columns and pnl_col:\n",
    "    dow_performance = merged_enriched.groupby('day_of_week')[pnl_col].agg(['mean', 'count'])\n",
    "    dow_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    dow_performance.index = [dow_names[i] for i in dow_performance.index]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PERFORMANCE BY DAY OF WEEK\")\n",
    "    print(\"=\"*60)\n",
    "    display(dow_performance)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(dow_performance.index, dow_performance['mean'], edgecolor='black', alpha=0.7)\n",
    "    plt.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.title('Average PnL by Day of Week', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Day of Week')\n",
    "    plt.ylabel('Average PnL ($)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment transition analysis - how does changing sentiment affect performance?\n",
    "if pnl_col and 'sentiment' in merged_df.columns:\n",
    "    transitions = analyzer.sentiment_transition_analysis(pnl_col)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SENTIMENT TRANSITION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Performance during sentiment shifts:\\n\")\n",
    "    display(transitions.head(15))\n",
    "    \n",
    "    # Visualize top transitions\n",
    "    top_transitions = transitions.head(10)\n",
    "    \n",
    "    fig = px.bar(top_transitions.reset_index(), x='transition', y='mean_pnl',\n",
    "                 title='Average PnL by Sentiment Transition',\n",
    "                 labels={'transition': 'Sentiment Transition', 'mean_pnl': 'Average PnL ($)'},\n",
    "                 hover_data=['count', 'median_pnl'])\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\")\n",
    "    fig.update_layout(height=500, xaxis_tickangle=-45)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a03988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "from features import create_rolling_features, create_time_features, create_sentiment_features\n",
    "\n",
    "# Add time features\n",
    "merged_enriched = create_time_features(merged_df)\n",
    "\n",
    "# Add rolling PnL features (if pnl_col exists)\n",
    "if pnl_col:\n",
    "    merged_enriched = create_rolling_features(\n",
    "        merged_enriched, \n",
    "        columns=[pnl_col],\n",
    "        windows=[3, 7],\n",
    "        group_col='account' if 'account' in merged_enriched.columns else None\n",
    "    )\n",
    "\n",
    "# Add sentiment features\n",
    "if 'sentiment' in merged_enriched.columns:\n",
    "    merged_enriched = create_sentiment_features(merged_enriched, windows=[3, 7])\n",
    "\n",
    "print(\"‚úì Features engineered successfully\")\n",
    "print(f\"  New shape: {merged_enriched.shape}\")\n",
    "print(f\"  New columns: {merged_enriched.shape[1] - merged_df.shape[1]}\")\n",
    "\n",
    "# Show sample of new features\n",
    "new_cols = [col for col in merged_enriched.columns if col not in merged_df.columns]\n",
    "print(f\"\\nNew feature columns: {new_cols[:10]}...\")  # Show first 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32aae9f",
   "metadata": {},
   "source": [
    "## 8. Pattern Discovery and Feature Engineering\n",
    "\n",
    "Identify patterns and create engineered features for deeper analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage analysis by sentiment\n",
    "leverage_cols = [col for col in merged_df.columns if 'leverage' in col.lower()]\n",
    "\n",
    "if leverage_cols and 'sentiment' in merged_df.columns:\n",
    "    leverage_col = leverage_cols[0]\n",
    "    leverage_by_sent = analyzer.leverage_by_sentiment(leverage_col)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LEVERAGE USAGE BY SENTIMENT\")\n",
    "    print(\"=\"*60)\n",
    "    display(leverage_by_sent)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    merged_df.boxplot(column=leverage_col, by='sentiment')\n",
    "    plt.title('Leverage Distribution by Market Sentiment', fontsize=14, fontweight='bold')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "    plt.xlabel('Sentiment', fontsize=12)\n",
    "    plt.ylabel('Leverage', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Leverage data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988bb614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag analysis - does past sentiment predict current performance?\n",
    "if pnl_col:\n",
    "    lag_results = analyzer.lag_analysis(pnl_col, max_lag=7)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LAG ANALYSIS: Past Sentiment vs Current Performance\")\n",
    "    print(\"=\"*60)\n",
    "    display(lag_results)\n",
    "    \n",
    "    # Visualize lag correlations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(lag_results['lag_days'], lag_results['correlation'], edgecolor='black', alpha=0.7)\n",
    "    plt.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Lag (Days)', fontsize=12)\n",
    "    plt.ylabel('Correlation with PnL', fontsize=12)\n",
    "    plt.title('Sentiment Lag Effect on Trading Performance', fontsize=14, fontweight='bold')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Annotate with significance\n",
    "    for idx, row in lag_results.iterrows():\n",
    "        if row['p_value'] < 0.05:\n",
    "            plt.text(row['lag_days'], row['correlation'], '**', ha='center', va='bottom', fontsize=14, color='red')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\\n** indicates statistically significant (p < 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a838925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis with p-values\n",
    "if pnl_col and 'sentiment_numeric' in merged_df.columns:\n",
    "    metrics_to_analyze = [col for col in merged_df.columns if any(keyword in col.lower() \n",
    "                          for keyword in ['pnl', 'size', 'leverage', 'win'])]\n",
    "    \n",
    "    if metrics_to_analyze:\n",
    "        corr_results = analyzer.correlation_analysis(metrics_to_analyze)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CORRELATION ANALYSIS: Sentiment vs Metrics\")\n",
    "        print(\"=\"*60)\n",
    "        display(corr_results.sort_values('correlation', key=abs, ascending=False))\n",
    "        print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix - numeric columns only\n",
    "numeric_cols = merged_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Filter to relevant columns\n",
    "relevant_cols = [col for col in numeric_cols if any(keyword in col.lower() \n",
    "                 for keyword in ['pnl', 'sentiment', 'leverage', 'size', 'win'])]\n",
    "\n",
    "if len(relevant_cols) > 2:\n",
    "    corr_matrix = merged_df[relevant_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Heatmap: Sentiment vs Performance Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough numeric columns for correlation analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by sentiment category\n",
    "from analysis import SentimentPerformanceAnalyzer\n",
    "\n",
    "if pnl_col and 'sentiment' in merged_df.columns:\n",
    "    analyzer = SentimentPerformanceAnalyzer(merged_df)\n",
    "    \n",
    "    perf_by_sentiment = analyzer.performance_by_sentiment(pnl_col)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"PERFORMANCE BY SENTIMENT CATEGORY\")\n",
    "    print(\"=\"*60)\n",
    "    display(perf_by_sentiment)\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d64af",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis: Sentiment vs Performance\n",
    "\n",
    "Analyze the relationship between market sentiment and trading performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceecc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account-level performance (if account column exists)\n",
    "if 'account' in merged_df.columns and pnl_col:\n",
    "    account_performance = merged_df.groupby('account').agg({\n",
    "        pnl_col: ['sum', 'mean', 'count'],\n",
    "    }).round(2)\n",
    "    \n",
    "    account_performance.columns = ['Total_PnL', 'Avg_PnL', 'Trade_Count']\n",
    "    account_performance = account_performance.sort_values('Total_PnL', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Traders by Total PnL:\")\n",
    "    display(account_performance.head(10))\n",
    "    \n",
    "    print(\"\\nBottom 10 Traders by Total PnL:\")\n",
    "    display(account_performance.tail(10))\n",
    "    \n",
    "    # Distribution of account performance\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].hist(account_performance['Total_PnL'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title('Distribution of Total PnL by Account', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Total PnL ($)')\n",
    "    axes[0].set_ylabel('Number of Accounts')\n",
    "    axes[0].axvline(0, color='red', linestyle='--', label='Break-even')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    axes[1].scatter(account_performance['Trade_Count'], account_performance['Total_PnL'], alpha=0.6)\n",
    "    axes[1].set_title('Trade Count vs Total PnL', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Number of Trades')\n",
    "    axes[1].set_ylabel('Total PnL ($)')\n",
    "    axes[1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall performance metrics\n",
    "if pnl_col:\n",
    "    total_pnl = merged_df[pnl_col].sum()\n",
    "    win_rate = (merged_df[pnl_col] > 0).sum() / len(merged_df) * 100\n",
    "    avg_win = merged_df[merged_df[pnl_col] > 0][pnl_col].mean()\n",
    "    avg_loss = merged_df[merged_df[pnl_col] < 0][pnl_col].mean()\n",
    "    profit_factor = abs(merged_df[merged_df[pnl_col] > 0][pnl_col].sum() / \n",
    "                       merged_df[merged_df[pnl_col] < 0][pnl_col].sum()) if merged_df[merged_df[pnl_col] < 0][pnl_col].sum() != 0 else np.inf\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"OVERALL PERFORMANCE METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total PnL: ${total_pnl:,.2f}\")\n",
    "    print(f\"Win Rate: {win_rate:.2f}%\")\n",
    "    print(f\"Average Win: ${avg_win:,.2f}\")\n",
    "    print(f\"Average Loss: ${avg_loss:,.2f}\")\n",
    "    print(f\"Profit Factor: {profit_factor:.2f}\")\n",
    "    print(f\"Risk/Reward Ratio: {abs(avg_win/avg_loss):.2f}\" if avg_loss != 0 else \"Risk/Reward: N/A\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f990c1",
   "metadata": {},
   "source": [
    "## 6. Trader Performance Metrics\n",
    "\n",
    "Calculate and visualize key performance indicators for traders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df54f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment frequency and duration analysis\n",
    "if 'sentiment' in sentiment_clean.columns:\n",
    "    # Calculate sentiment streaks (consecutive days)\n",
    "    sentiment_clean['sentiment_change'] = (sentiment_clean['sentiment'] != sentiment_clean['sentiment'].shift()).astype(int)\n",
    "    sentiment_clean['streak_id'] = sentiment_clean['sentiment_change'].cumsum()\n",
    "    \n",
    "    streak_lengths = sentiment_clean.groupby(['streak_id', 'sentiment']).size().reset_index(name='duration')\n",
    "    \n",
    "    print(\"Sentiment Streak Statistics:\")\n",
    "    print(streak_lengths.groupby('sentiment')['duration'].describe())\n",
    "    \n",
    "    # Visualize streak durations\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    for sentiment_val in streak_lengths['sentiment'].unique():\n",
    "        subset = streak_lengths[streak_lengths['sentiment'] == sentiment_val]['duration']\n",
    "        axes[0].hist(subset, alpha=0.6, label=sentiment_val, bins=20, edgecolor='black')\n",
    "    \n",
    "    axes[0].set_title('Distribution of Sentiment Streak Durations', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Days in Streak')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Pie chart of total days by sentiment\n",
    "    sentiment_totals = sentiment_clean['sentiment'].value_counts()\n",
    "    axes[1].pie(sentiment_totals.values, labels=sentiment_totals.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title('Proportion of Days by Sentiment', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22861647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment over time - line chart with numeric encoding\n",
    "if 'sentiment_numeric' in sentiment_clean.columns:\n",
    "    fig = px.line(sentiment_clean, x='date', y='sentiment_numeric', \n",
    "                  title='Bitcoin Market Sentiment Over Time',\n",
    "                  labels={'sentiment_numeric': 'Sentiment (-2=Extreme Fear, 2=Extreme Greed)', 'date': 'Date'},\n",
    "                  hover_data=['sentiment'])\n",
    "    \n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Neutral\")\n",
    "    fig.update_layout(height=500, hovermode='x unified')\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Sentiment numeric encoding not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8056bed1",
   "metadata": {},
   "source": [
    "## 5. Sentiment Distribution Analysis\n",
    "\n",
    "Deep dive into how sentiment (Fear/Greed) is distributed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca79eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of key metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "if pnl_col:\n",
    "    # PnL distribution\n",
    "    axes[0, 0].hist(merged_df[pnl_col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(merged_df[pnl_col].mean(), color='red', linestyle='--', label=f'Mean: ${merged_df[pnl_col].mean():.2f}')\n",
    "    axes[0, 0].set_title('PnL Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('PnL ($)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Sentiment distribution\n",
    "if 'sentiment' in merged_df.columns:\n",
    "    sentiment_counts = merged_df['sentiment'].value_counts()\n",
    "    axes[0, 1].bar(sentiment_counts.index, sentiment_counts.values, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].set_title('Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Sentiment')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Trade count distribution over time\n",
    "if 'date' in merged_df.columns and pnl_col:\n",
    "    daily_trades = merged_df.groupby('date').size()\n",
    "    axes[1, 0].plot(daily_trades.index, daily_trades.values, alpha=0.7)\n",
    "    axes[1, 0].set_title('Daily Trading Activity', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Date')\n",
    "    axes[1, 0].set_ylabel('Number of Records')\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Cumulative PnL over time\n",
    "if pnl_col and 'date' in merged_df.columns:\n",
    "    cumulative_pnl = merged_df.groupby('date')[pnl_col].sum().cumsum()\n",
    "    axes[1, 1].plot(cumulative_pnl.index, cumulative_pnl.values, linewidth=2, alpha=0.8)\n",
    "    axes[1, 1].set_title('Cumulative PnL Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Date')\n",
    "    axes[1, 1].set_ylabel('Cumulative PnL ($)')\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf374d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric columns\n",
    "print(\"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "display(merged_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223fe4ba",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Summary statistics and initial exploration of the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check merge quality - how many records matched?\n",
    "print(\"Merge Quality Check:\")\n",
    "print(f\"Records with sentiment data: {merged_df['sentiment'].notna().sum():,} ({merged_df['sentiment'].notna().sum()/len(merged_df)*100:.1f}%)\")\n",
    "print(f\"Records without sentiment: {merged_df['sentiment'].isna().sum():,}\")\n",
    "\n",
    "# Show sentiment distribution in merged data\n",
    "if 'sentiment' in merged_df.columns:\n",
    "    print(\"\\nSentiment Distribution in Merged Data:\")\n",
    "    print(merged_df['sentiment'].value_counts())\n",
    "    print(f\"\\nSentiment Numeric Distribution:\")\n",
    "    print(merged_df['sentiment_numeric'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4140ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify PnL column for analysis\n",
    "pnl_columns = [col for col in merged_df.columns if 'pnl' in col.lower() or 'closedpnl' in col.lower()]\n",
    "print(f\"PnL columns found: {pnl_columns}\")\n",
    "\n",
    "if pnl_columns:\n",
    "    pnl_col = pnl_columns[0]  # Use first PnL column\n",
    "    print(f\"\\nUsing '{pnl_col}' as main PnL metric\")\n",
    "    \n",
    "    # Basic PnL stats\n",
    "    print(f\"\\nPnL Statistics:\")\n",
    "    print(f\"  Total PnL: ${merged_df[pnl_col].sum():,.2f}\")\n",
    "    print(f\"  Mean PnL: ${merged_df[pnl_col].mean():,.2f}\")\n",
    "    print(f\"  Median PnL: ${merged_df[pnl_col].median():,.2f}\")\n",
    "    print(f\"  Std Dev: ${merged_df[pnl_col].std():,.2f}\")\n",
    "    print(f\"  Win Rate: {(merged_df[pnl_col] > 0).sum() / len(merged_df) * 100:.2f}%\")\n",
    "else:\n",
    "    pnl_col = None\n",
    "    print(\"‚ö†Ô∏è No PnL column found. Some analyses may be limited.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54959dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge trading performance with sentiment (including lags)\n",
    "merged_df = preprocessor.merge_with_sentiment(\n",
    "    daily_performance, \n",
    "    sentiment_clean,\n",
    "    lag_days=[0, 1, 3, 7]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì Datasets merged successfully\")\n",
    "print(f\"  Total records: {len(merged_df):,}\")\n",
    "print(f\"  Columns: {len(merged_df.columns)}\")\n",
    "print(f\"  Date range: {merged_df['date'].min()} to {merged_df['date'].max()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "display(merged_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebc286",
   "metadata": {},
   "source": [
    "## 3. Merge Datasets on Date/Time\n",
    "\n",
    "Merge sentiment data with trader performance data, including lagged sentiment features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5178d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values after preprocessing\n",
    "print(\"Missing Values in Historical Data:\")\n",
    "missing_hist = historical_clean.isnull().sum()\n",
    "print(missing_hist[missing_hist > 0] if any(missing_hist > 0) else \"None\")\n",
    "\n",
    "print(\"\\nMissing Values in Sentiment Data:\")\n",
    "missing_sent = sentiment_clean.isnull().sum()\n",
    "print(missing_sent[missing_sent > 0] if any(missing_sent > 0) else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d841ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate trading data to daily account-level metrics\n",
    "daily_performance = preprocessor.aggregate_daily_performance(historical_clean)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì Trading data aggregated to daily performance\")\n",
    "display(daily_performance.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243cb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess historical trading data\n",
    "historical_clean = preprocessor.preprocess_historical(historical_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì Historical data preprocessed\")\n",
    "print(f\"  Date range: {historical_clean['date'].min()} to {historical_clean['date'].max()}\")\n",
    "print(f\"  Total trades: {len(historical_clean):,}\")\n",
    "display(historical_clean.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess both datasets\n",
    "from preprocessing import DataPreprocessor, create_sentiment_numeric_encoding\n",
    "\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Preprocess sentiment data\n",
    "sentiment_clean = preprocessor.preprocess_sentiment(sentiment_df)\n",
    "sentiment_clean = create_sentiment_numeric_encoding(sentiment_clean)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì Sentiment data preprocessed\")\n",
    "print(f\"  Date range: {sentiment_clean['date'].min()} to {sentiment_clean['date'].max()}\")\n",
    "print(f\"  Total days: {len(sentiment_clean)}\")\n",
    "display(sentiment_clean.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73129723",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Cleaning\n",
    "\n",
    "Clean both datasets, handle missing values, and standardize column formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50173b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and memory usage\n",
    "print(\"HISTORICAL DATA INFO:\")\n",
    "print(historical_df.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nSENTIMENT DATA INFO:\")\n",
    "print(sentiment_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the datasets\n",
    "print(\"=\"*60)\n",
    "print(\"HISTORICAL TRADING DATA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {historical_df.shape}\")\n",
    "print(f\"\\nColumns ({len(historical_df.columns)}):\")\n",
    "print(historical_df.columns.tolist())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(historical_df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SENTIMENT DATA (Fear/Greed Index)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {sentiment_df.shape}\")\n",
    "print(f\"\\nColumns ({len(sentiment_df.columns)}):\")\n",
    "print(sentiment_df.columns.tolist())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(sentiment_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets using custom data loader\n",
    "from data_loader import DataLoader\n",
    "\n",
    "loader = DataLoader(data_dir='../data')\n",
    "\n",
    "try:\n",
    "    historical_df, sentiment_df = loader.load_all()\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úì Datasets loaded successfully!\")\n",
    "    print(\"=\"*60)\n",
    "except FileNotFoundError as e:\n",
    "    print(\"\\n‚ö†Ô∏è ERROR: Datasets not found!\")\n",
    "    print(\"\\nüì• NEXT STEPS:\")\n",
    "    print(\"1. Download 'historical_data.csv' from:\")\n",
    "    print(\"   https://drive.google.com/file/d/1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs/view\")\n",
    "    print(\"\\n2. Download 'fear_greed_index.csv' from:\")\n",
    "    print(\"   https://drive.google.com/file/d/1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf/view\")\n",
    "    print(\"\\n3. Place both files in the '../data/' directory\")\n",
    "    print(\"\\n4. Re-run this cell\")\n",
    "    print(\"=\"*60)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8494dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data quality\n",
    "validation_hist = loader.validate_data(historical_df, \"Historical Trading Data\")\n",
    "validation_sent = loader.validate_data(sentiment_df, \"Sentiment Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaca9e9",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Datasets\n",
    "\n",
    "First, we'll import necessary libraries and load both datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
